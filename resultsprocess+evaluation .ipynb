{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb971e-ada1-44f6-a4d4-cd43c676616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1del noise first\n",
    "import re\n",
    "\n",
    "def extract_movies(file_path, output_path):\n",
    "    # Modified regular expression to correctly identify movie titles with strict numbering format\n",
    "    movie_pattern = re.compile(r'(\\d+\\.\\s)(.*?)(?=(?:\\d+\\.\\s)|$)')\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "        for idx, line in enumerate(lines):\n",
    "            # Remove content after <|endofmessage|> if it exists\n",
    "            if \"<|endofmessage|>\" in line:\n",
    "                line = line.split(\"<|endofmessage|>\")[0]\n",
    "            \n",
    "            # Find all movies in the line using the regex pattern\n",
    "            movies = movie_pattern.findall(line)\n",
    "            \n",
    "            # Extract only the movie title (ignore the numbering part)\n",
    "            cleaned_movies = [title.strip() for _, title in movies]\n",
    "            \n",
    "            # We are interested only in the top 5 movies\n",
    "            top_five = cleaned_movies[:5]\n",
    "            \n",
    "            # Adjust line number to start from 1001\n",
    "            line_number = idx + 1\n",
    "            \n",
    "            if top_five:\n",
    "                # Format output as specified\n",
    "                formatted_output = \"\\n\".join([f\"{i+1}. {movie}\" for i, movie in enumerate(top_five)])\n",
    "                output_file.write(f\"Line {line_number}:\\n{formatted_output}\\n\\n\")\n",
    "            else:\n",
    "                output_file.write(f\"Line {line_number}: No valid movie data found\\n\\n\")\n",
    "\n",
    "# Usage\n",
    "extract_movies('inferenceresult.txt', 'extracted_movies__01.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13306488-b05e-400e-92ad-915ed72b78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2del these\n",
    "import re\n",
    "\n",
    "def clean_recommendations(file_path, cleaned_output_path):\n",
    "    # Regular expression to identify \"These recommendations\" and anything following it\n",
    "    recommendations_pattern = re.compile(r'These recommendations.*', re.IGNORECASE)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    with open(cleaned_output_path, 'w', encoding='utf-8') as cleaned_file:\n",
    "        for line in lines:\n",
    "            # Remove \"These recommendations\" and following content if it exists\n",
    "            cleaned_line = recommendations_pattern.sub('', line)\n",
    "            cleaned_file.write(cleaned_line)\n",
    "\n",
    "# Usage\n",
    "clean_recommendations('extracted_movies__01.txt', 'cleaned_extracted_movies01test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba48c23-be6f-4163-97a1-518ee1b3e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3del \"\"\n",
    "import re\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = \"cleaned_extracted_movies01test.txt\"\n",
    "output_file = \"cleaned_output.txt\"\n",
    "\n",
    "# Function to remove extra double quotes\n",
    "def clean_quotes(text):\n",
    "    # Match and remove extra double quotes in pairs\n",
    "    return re.sub(r'\"\"([^\"]+?)\"\"', r'\\1', text)\n",
    "\n",
    "# Read the file, process the content, and write to a new file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_quotes(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81497170-741f-412d-9b6e-eb87effb5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4del |\n",
    "import re\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = \"cleaned_output.txt\"\n",
    "output_file = \"final_output.txt\"\n",
    "\n",
    "# Function processes the fifth item and deletes the part after \"|\"\n",
    "def clean_fifth_item(line):\n",
    "    # Match the content after \"5.\" until the end of the line\n",
    "    match = re.search(r\"(5\\.\\s)(.*?)(\\|.*)?$\", line)\n",
    "    if match:\n",
    "        # If the match is found and contains \"|\", only the content before \"|\" is retained and a blank line is added after the line\n",
    "        return line[:match.start(3)] + \"\\n\" if match.group(3) else line\n",
    "    return line\n",
    "\n",
    "# Read the file, process each line, and write to a new file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_fifth_item(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0b506-ecc6-4b3c-8642-a45ce1290a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5del this\n",
    "import re\n",
    "input_file = \"final_output.txt\"\n",
    "output_file = \"final_cleaned_output.txt\"\n",
    "\n",
    "\n",
    "def clean_fifth_item_with_this(line):\n",
    "    \n",
    "    match = re.search(r\"(5\\.\\s.*?)(This\\b.*)?$\", line)\n",
    "    if match and match.group(2):\n",
    "       \n",
    "        return line[:match.start(2)] + \"\\n\"\n",
    "    return line\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_fifth_item_with_this(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffa29f-cf38-4c90-862b-774e756451bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6del the\n",
    "import re\n",
    "\n",
    "input_file = \"final_cleaned_output.txt\"\n",
    "output_file = \"final_processed_output.txt\"\n",
    "\n",
    "def clean_fifth_item_with_the(line):\n",
    "    \n",
    "    match = re.search(r\"(5\\.\\s.*?)(The\\b.*)?$\", line)\n",
    "    if match and match.group(2):\n",
    "        \n",
    "        return line[:match.start(2)] + \"\\n\"\n",
    "    return line\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_fifth_item_with_the(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18a61b-2518-404e-9880-5c6c4f067ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7del these\n",
    "import re\n",
    "\n",
    "input_file = \"final_processed_output.txt\"\n",
    "output_file = \"final_reviewed_output.txt\"\n",
    "\n",
    "def clean_fifth_item_with_these(line):\n",
    "    \n",
    "    match = re.search(r\"(5\\.\\s.*?)(These\\b.*)?$\", line)\n",
    "    if match and match.group(2):\n",
    "        \n",
    "        return line[:match.start(2)] + \"\\n\"\n",
    "    return line\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_fifth_item_with_these(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0b827-87f8-438f-b224-4d3895dae348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8del note\n",
    "import re\n",
    "\n",
    "input_file = \"final_reviewed_output.txt\"\n",
    "output_file = \"final.txt\"\n",
    "\n",
    "def clean_fifth_item_with_note(line):\n",
    "    \n",
    "    match = re.search(r\"(5\\.\\s.*?)(Note\\b.*)?$\", line)\n",
    "    if match and match.group(2):\n",
    "        \n",
    "        return line[:match.start(2)] + \"\\n\"\n",
    "    return line\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_fifth_item_with_note(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f0a10-7eea-447f-bff6-777fefa6cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9del has\n",
    "import re\n",
    "\n",
    "input_file = \"final.txt\"\n",
    "output_file = \"cleaned_final.txt\"\n",
    "\n",
    "def clean_item_with_has(line):\n",
    "    \n",
    "    match = re.search(r\"(\\d\\.\\s.*?)(\\s\\(has\\b.*)?$\", line)\n",
    "    if match and match.group(2):\n",
    "        \n",
    "        return line[:match.start(2)] + \"\\n\"\n",
    "    return line\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_item_with_has(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11bc27c-213f-440d-933a-8f00be8b364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10del a\n",
    "import re\n",
    "\n",
    "input_file = \"cleaned_final.txt\"\n",
    "output_file = \"final_output_cleaned.txt\"\n",
    "\n",
    "def clean_item_with_dash_a(line):\n",
    "    \n",
    "    match = re.search(r\"(\\d\\.\\s.*?)(\\s-\\sa\\s.*)?$\", line)\n",
    "    if match and match.group(2):\n",
    "        \n",
    "        return line[:match.start(2)] + \"\\n\"\n",
    "    return line\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_item_with_dash_a(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c14f43-44f3-4a86-88f7-6fa370892189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11del this\n",
    "import re\n",
    "\n",
    "input_file = \"final_output_cleaned.txt\"\n",
    "output_file = \"cleaned_final_output_with_this_removed.txt\"\n",
    "\n",
    "def clean_item_with_this(line):\n",
    "   \n",
    "    match = re.search(r\"(\\d\\.\\s.*?)(\\s-\\sThis\\b.*)?$\", line)\n",
    "    if match and match.group(2):\n",
    "        \n",
    "        return line[:match.start(2)] + \"\\n\"\n",
    "    return line\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        cleaned_line = clean_item_with_this(line)\n",
    "        outfile.write(cleaned_line)\n",
    "\n",
    "print(\"Processing completed, results saved\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140e97e-95c5-4090-baec-ad2f6b0dca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12del lots\n",
    "import re\n",
    "\n",
    "def clean_lines_by_rules(file_path, cleaned_output_path, rules):\n",
    "\n",
    "    pattern = re.compile(rf'({\"|\".join(map(re.escape, rules))}).*')\n",
    "\n",
    "    try:\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        \n",
    "        with open(cleaned_output_path, 'w', encoding='utf-8') as cleaned_file:\n",
    "            for line in lines:\n",
    "                \n",
    "                cleaned_line = pattern.sub('', line)\n",
    "                cleaned_file.write(cleaned_line)\n",
    "        \n",
    "        print(f\"Cleaning is complete and the processed files have been saved to {cleaned_output_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"file not found：{file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred：{e}\")\n",
    "\n",
    "rules = [\n",
    "    \" (liked by\",\n",
    "    \" (1 liked\",\n",
    "    \" (Jaccard\",\n",
    "    \" (fantasy\",\n",
    "    \" (drama\",\n",
    "    \" (historical\",\n",
    "    \" - 1 (liked\",\n",
    "    \" - 2 (liked\",\n",
    "    \" - 3 (liked\",\n",
    "    \" - 2 (common\",\n",
    "    \" - 0.\",\n",
    "    \" - 1 (common\",\n",
    "    \" - The user\",\n",
    "    \" - As\",\n",
    "    \" - Another\",\n",
    "    \" - Although\",\n",
    "    \" - Similarity\",\n",
    "    \" (a drama\",\n",
    "    \" (similar\",\n",
    "    \" (Action\",\n",
    "    \" (Romantic\",\n",
    "    \" (Family\",\n",
    "    \" - 4 common\",\n",
    "    \" - 3 common\",\n",
    "    \" - an action\",\n",
    "    \" - 1 actor\",\n",
    "    \" - 0 actors\",\n",
    "    \" (directed\",\n",
    "    \" (e.g.\",\n",
    "    \" (Directed\",\n",
    "    \" (an action\"\n",
    "]\n",
    "\n",
    "clean_lines_by_rules('cleaned_final_output_with_this_removed.txt', '555.txt', rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed951499-b293-4b14-9527-0e401dc7da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13add\n",
    "def merge_files(file_list, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for file in file_list:\n",
    "            with open(file, 'r', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\")  # Add a new line between file contents \n",
    "\n",
    "# List of input files\n",
    "files_to_merge = [\n",
    "    '555.txt'\n",
    "]\n",
    "\n",
    "# Output file path\n",
    "output_file = 'merged_movies.txt'\n",
    "\n",
    "# Call the function to merge the files\n",
    "merge_files(files_to_merge, output_file)\n",
    "\n",
    "print(f\"Files have been merged into {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7be300-8250-4b14-8be4-6a3e50fd9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def convert_to_csv(input_file, output_csv):\n",
    "    # Regular expression to match movie titles and line numbers\n",
    "    line_pattern = re.compile(r'Line\\s*(\\d+):')\n",
    "    movie_pattern = re.compile(r'\\d+\\.\\s*(.*?)\\s*(?=\\d+\\.|$)')\n",
    "    \n",
    "    # Open the output CSV file\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        csv_writer.writerow(['Line Number', 'Movie 1', 'Movie 2', 'Movie 3', 'Movie 4', 'Movie 5'])\n",
    "        \n",
    "        with open(input_file, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            current_line_num = None\n",
    "            current_movies = []\n",
    "            \n",
    "            for line in lines:\n",
    "                # Check for line number (e.g., Line 1:)\n",
    "                line_match = line_pattern.search(line)\n",
    "                if line_match:\n",
    "                    # we have already collected movies for the previous line, write them to the CSV\n",
    "                    if current_line_num and len(current_movies) == 5:\n",
    "                        csv_writer.writerow([current_line_num] + current_movies)\n",
    "                    # Reset for new line\n",
    "                    current_line_num = line_match.group(1)\n",
    "                    current_movies = []\n",
    "                \n",
    "                # Find all movies in the current line\n",
    "                movies = movie_pattern.findall(line)\n",
    "                if movies:\n",
    "                    current_movies.extend(movies)\n",
    "            \n",
    "            # Write the last set of movies if the file ends after a line\n",
    "            if current_line_num and len(current_movies) == 5:\n",
    "                csv_writer.writerow([current_line_num] + current_movies)\n",
    "\n",
    "# Usage\n",
    "input_file = 'merged_movies.txt'\n",
    "output_csv = 'movies_recommendations.csv'\n",
    "\n",
    "convert_to_csv(input_file, output_csv)\n",
    "\n",
    "print(f\"CSV file created at: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196be3b-4d77-4232-bbf5-e020d764535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15 add gd\n",
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "movies_recommendations = pd.read_csv('movies_recommendations.csv')\n",
    "match_output = pd.read_csv('gt-match-output.csv')\n",
    "\n",
    "# Merge the files based on the 'Line Number' from movies_recommendations and 'index' from match_output\n",
    "merged_df = pd.merge(movies_recommendations, match_output[['index', 'movie_name']], how='left', left_on='Line Number', right_on='index')\n",
    "\n",
    "# Drop the extra 'index' column after the merge\n",
    "merged_df = merged_df.drop(columns=['index'])\n",
    "\n",
    "# Save the merged result to a new CSV file\n",
    "output_file = 'merged_with_movie_name.csv'\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"CSV file created at: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac90fc-7416-4a6d-8222-4af8adc77292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gd name\n",
    "import pandas as pd\n",
    "\n",
    "# Load the merged CSV file\n",
    "merged_df = pd.read_csv('merged_with_movie_name.csv')\n",
    "\n",
    "# Function to check if the movie_name matches any of Movie1 to Movie5\n",
    "def check_match(row):\n",
    "    for i in range(1, 6):\n",
    "        if row['movie_name'] == row[f'Movie {i}']:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "# Apply the check_match function to each row and create a new column for the result\n",
    "merged_df['Match'] = merged_df.apply(check_match, axis=1)\n",
    "\n",
    "# Save the updated dataframe with the new column\n",
    "output_file_with_match = 'merged_with_match_column.csv'\n",
    "merged_df.to_csv(output_file_with_match, index=False)\n",
    "\n",
    "print(f\"CSV file created at: {output_file_with_match}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c352e8b-7fee-42d3-ad78-e5a2cecd7841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged CSV file with the match column\n",
    "df = pd.read_csv('merged_with_match_column.csv')\n",
    "\n",
    "# Function to calculate Hit@n\n",
    "def calculate_hit(df, n):\n",
    "    return df['Match'].apply(lambda x: 1 if 0 < x <= n else 0).mean()\n",
    "\n",
    "# Function to calculate DCG@n and NDCG@n for each row\n",
    "def calculate_dcg(row, n):\n",
    "    match = row['Match']\n",
    "    if 0 < match <= n:  # if there's a match in the top n\n",
    "        return 1 / np.log2(match + 1)\n",
    "    return 0\n",
    "\n",
    "# Function to calculate NDCG@n\n",
    "def calculate_ndcg(df, n):\n",
    "    # Calculate DCG@n for each row\n",
    "    df[f'DCG@{n}'] = df.apply(lambda row: calculate_dcg(row, n), axis=1)\n",
    "    # Ideal DCG@n (IDCG@n) is always 1, since the best match is in the first position\n",
    "    idcg = 1 / np.log2(2)\n",
    "    # Calculate NDCG@n for each row\n",
    "    df[f'NDCG@{n}'] = df[f'DCG@{n}'] / idcg\n",
    "    return df[f'NDCG@{n}'].mean()\n",
    "\n",
    "# Calculate Hit@3 and NDCG@3\n",
    "hit_at_3 = calculate_hit(df, 3)\n",
    "ndcg_at_3 = calculate_ndcg(df, 3)\n",
    "\n",
    "# Calculate Hit@5 and NDCG@5\n",
    "hit_at_5 = calculate_hit(df, 5)\n",
    "ndcg_at_5 = calculate_ndcg(df, 5)\n",
    "\n",
    "# Scale factor\n",
    "scale_factor = 508 / 6040\n",
    "\n",
    "# Scaled results\n",
    "scaled_hit_at_3 = hit_at_3 * scale_factor\n",
    "scaled_ndcg_at_3 = ndcg_at_3 * scale_factor\n",
    "scaled_hit_at_5 = hit_at_5 * scale_factor\n",
    "scaled_ndcg_at_5 = ndcg_at_5 * scale_factor\n",
    "\n",
    "# Output the results\n",
    "print(f\"Hit@3: {hit_at_3}\")\n",
    "print(f\"NDCG@3: {ndcg_at_3}\")\n",
    "print(f\"Hit@5: {hit_at_5}\")\n",
    "print(f\"NDCG@5: {ndcg_at_5}\")\n",
    "\n",
    "print(\"\\n### Scaled Results (Multiplied by 508 / 6040) ###\")\n",
    "print(f\"Scaled Hit@3: {scaled_hit_at_3}\")\n",
    "print(f\"Scaled NDCG@3: {scaled_ndcg_at_3}\")\n",
    "print(f\"Scaled Hit@5: {scaled_hit_at_5}\")\n",
    "print(f\"Scaled NDCG@5: {scaled_ndcg_at_5}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
